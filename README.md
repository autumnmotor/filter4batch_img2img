# webuiのbatchimg2imgのための時間軸的因果付与フィルター

## 説明
https://github.com/AUTOMATIC1111/stable-diffusion-webui

stable-diffusion-webuiのbatchimg2imgは各画像の因果性を考慮せず、個々に独立に画像を生成する。

一方で、連続した画像、動画ファイルの連番切り出し画像などをbatchimg2imgで処理し、AIにレタッチさせたい、という需要は少なからずある。
しかし、そうした連続性のある、時間軸に沿ったシーケンシャルな画像に対しても、batchimg2imgは各画像の前後関係、シーケンシャルな時間関係を考慮せず、バラバラに画像を出力し、結果として「ちらつき」に満ちた、まとまりのない、ギクシャクした画像群を生成する。

このリポジトリではそうした、短時間における一貫性のなさを解消するための、時間軸を考慮した因果性を与えるフィルターを提供する。

## 使い方
https://github.com/megvii-research/ECCV2022-RIFE

上記のリポジトリをクローンし、モデルファイルなどダウンロードし、inference_img.pyが正常に動作できるように環境を整える。
上記のリポジトリをクローンしたディレクトリに、このリポジトリ上のfilter4batchi2i.pyを置き、実行する（うーん、いい加減）。

## パラメータ
- --inputdir　入力ディレクトリ。ここにbatchi2iの出力結果の画像ファイル群を置く。
- --outputdir　出力ディレクトリ。ここに連番画像フィルター処理のファイルが出力される。
- --deflicker_times　ちらつき軽減処理を抑える回数。フィルター出力結果の「ボケ」が気になるなら、回数を増やす（処理時間は増える）。
- --deblur_times　ブレ軽減処理を抑える回数。フィルター出力結果の「ブレ」が気になるなら、回数を増やす（処理時間は増える）。
- --model　モデルの場所（ディレクトリ）を記述する。デフォルトでOK。


## 原理
基本的にはi2iの出力結果を連続した画像とみなし、LPF(ローパスフィルター)をかけ、リバーブ（モーションブラー）をかけ、そうして画像間の時間軸的因果関係を仮定して、ぼやかすように混合する。混合するだけでは「ボケ」、「ブレ」が出るだけなので、--deflicker_times、--deblur_timesで混合の具合を調節する。
